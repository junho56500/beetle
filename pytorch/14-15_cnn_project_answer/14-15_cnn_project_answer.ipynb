{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023, Acadential, All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14-15. 직접 만든 CNN 모델과 ResNet, VGGNet을 활용한 CV 프로젝트\n",
    "\n",
    "이번 시간에는 저희가 만든 CNN 모델, torchvision에서 제공되는 VGGNet, ResNet들을 사용하여 이미지를 분류하는 프로젝트를 진행해보겠습니다. \\\n",
    "저희가 사용할 데이터셋은 CIFAR10 데이터셋으로 저희가 Section 2, Section 12에서 사용했던 데이터셋과 동일한 데이터셋입니다.\n",
    "\n",
    "- Custom Model\n",
    "- VGG without Batch Norm\n",
    "- VGG with Batch Norm\n",
    "- ResNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Drive을 Colab에 Mount하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# import os\n",
    "# drive.mount('/content/drive')\n",
    "# os.chdir(\"/content/drive/MyDrive/Lesson/인프런 강의 - 딥러닝 이론 실무 완전 정복/practicals/section_14/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import os\n",
    "\n",
    "# CIFAR10 데이터셋 불러오기\n",
    "from src.cifar10 import get_dataloaders\n",
    "\n",
    "# Train val loop 불러오기\n",
    "from src.train_val import train_loop, val_loop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataloaders\n",
    "\n",
    "dataloader = get_dataloaders()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "# Define device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (12): Flatten(start_dim=1, end_dim=-1)\n",
       "    (13): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import NeuralNetwork\n",
    "from torch import nn\n",
    "from src.model import NeuralNetwork\n",
    "\n",
    "# Instantiate Model\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "                            lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "test_loss_history = []\n",
    "test_acc_history = []\n",
    "best_acc = 0.\n",
    "\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"------------------Epoch {epoch} Train------------------\")\n",
    "    # Train Loop\n",
    "    train_loop(model, dataloader, loss_fn, optimizer)\n",
    "    \n",
    "    print(f\"------------------Epoch {epoch} Test------------------\")\n",
    "    # Test Loop\n",
    "    val_loop(model, dataloader, loss_fn)\n",
    "    \n",
    "    # Save Best Checkpoint\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_summary = {\"custom_model\": train_loss_list}\n",
    "train_acc_summary = {\"custom_model\": train_acc_list}\n",
    "test_loss_summary = {\"custom_model\": test_loss_list}\n",
    "test_acc_summary = {\"custom_model\": test_acc_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG without Batch Norm (random init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VGG11 model\n",
    "\n",
    "# Instantiate model\n",
    "\n",
    "# Move model to device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "                            lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "test_loss_history = []\n",
    "test_acc_history = []\n",
    "best_acc = 0.\n",
    "\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"------------------Epoch {epoch} Train------------------\")\n",
    "    # Train Loop\n",
    "    \n",
    "    print(f\"------------------Epoch {epoch} Test------------------\")\n",
    "    # Test Loop\n",
    "\n",
    "    # Save Best Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_summary[\"vgg11\"] = train_loss_list\n",
    "train_acc_summary[\"vgg11\"] = train_acc_list\n",
    "test_loss_summary[\"vgg11\"] = test_loss_list\n",
    "test_acc_summary[\"vgg11\"] = test_acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG with Batch Norm (random init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VGG11 model with Batch Norm\n",
    "\n",
    "# Instantiate model\n",
    "\n",
    "# Move model to device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "                            lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "test_loss_history = []\n",
    "test_acc_history = []\n",
    "best_acc = 0.\n",
    "\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"------------------Epoch {epoch} Train------------------\")\n",
    "    # Train Loop\n",
    "    \n",
    "    print(f\"------------------Epoch {epoch} Test------------------\")\n",
    "    # Test Loop\n",
    "\n",
    "    # Save Best Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_summary[\"vgg11_bn\"] = train_loss_list\n",
    "train_acc_summary[\"vgg11_bn\"] = train_acc_list\n",
    "test_loss_summary[\"vgg11_bn\"] = test_loss_list\n",
    "test_acc_summary[\"vgg11_bn\"] = test_acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet (random init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VGG11 model with ResNet18 (randomly initialized)\n",
    "\n",
    "# Instantiate model\n",
    "\n",
    "# Move model to device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "                            lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "test_loss_history = []\n",
    "test_acc_history = []\n",
    "best_acc = 0.\n",
    "\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"------------------Epoch {epoch} Train------------------\")\n",
    "    # Train Loop\n",
    "    \n",
    "    print(f\"------------------Epoch {epoch} Test------------------\")\n",
    "    # Test Loop\n",
    "\n",
    "    # Save Best Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_summary[\"resnet18\"] = train_loss_list\n",
    "train_acc_summary[\"resnet18\"] = train_acc_list\n",
    "test_loss_summary[\"resnet18\"] = test_loss_list\n",
    "test_acc_summary[\"resnet18\"] = test_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "pd.DataFrame(train_loss_summary).to_csv('results/train_loss_summary.csv')\n",
    "pd.DataFrame(train_acc_summary).to_csv('results/train_acc_summary.csv')\n",
    "pd.DataFrame(test_loss_summary).to_csv('results/test_loss_summary.csv')\n",
    "pd.DataFrame(test_acc_summary).to_csv('results/test_acc_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_acc_summary[\"custom_model\"], label=\"custom_model\")\n",
    "plt.plot(train_acc_summary[\"vgg11\"], label=\"vgg11\")\n",
    "plt.plot(train_acc_summary[\"vgg11_bn\"], label=\"vgg11_bn\")\n",
    "plt.plot(train_acc_summary[\"resnet18\"], label=\"resnet18\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Train Accuracy\")\n",
    "plt.title(\"Train accuracy vs epochs\")\n",
    "plt.legend()\n",
    "plt.savefig(\"figures/train_acc_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(test_acc_summary[\"custom_model\"], label=\"custom_model\")\n",
    "plt.plot(test_acc_summary[\"vgg11\"], label=\"vgg11\")\n",
    "plt.plot(test_acc_summary[\"vgg11_bn\"], label=\"vgg11_bn\")\n",
    "plt.plot(test_acc_summary[\"resnet18\"], label=\"resnet18\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Test accuracy vs epochs\")\n",
    "plt.legend()\n",
    "plt.savefig(\"figures/test_acc_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(test_loss_summary[\"custom_model\"], label=\"custom_model\")\n",
    "plt.plot(test_loss_summary[\"vgg11\"], label=\"vgg11\")\n",
    "plt.plot(test_loss_summary[\"vgg11_bn\"], label=\"vgg11_bn\")\n",
    "plt.plot(test_loss_summary[\"resnet18\"], label=\"resnet18\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Test Loss\")\n",
    "plt.title(\"Test loss vs epochs\")\n",
    "plt.legend()\n",
    "plt.savefig(\"figures/test_loss_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
